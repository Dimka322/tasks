{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13-8WOSCB6JLP7h2d_OSIVqxau0eHHK9n",
      "authorship_tag": "ABX9TyPjgHgrByzIxhhOof+RptEA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimka322/tasks/blob/main/ralpth_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пьянков Дмитрий."
      ],
      "metadata": {
        "id": "h1TyPC00kKeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install free-proxy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcieN9Ne7Zrf",
        "outputId": "9c3bb266-7ba4-4a71-99ce-135b851029ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: free-proxy in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from free-proxy) (4.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from free-proxy) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fp.fp import FreeProxy\n",
        "import shutil"
      ],
      "metadata": {
        "id": "sn_wKVDI92Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proxy = FreeProxy(country_id=['US', 'BR', 'FR', 'NL', 'JP', 'SG']).get_proxy_list(repeat=2)"
      ],
      "metadata": {
        "id": "Z2_3r6vZ96eK"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proxy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bATfbDjs98FG",
        "outputId": "693045f4-5f09-4549-cef6-c3bc7834b7b0"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://209.79.65.132:8080'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "azrvAJW8uifQ"
      },
      "outputs": [],
      "source": [
        "import requests, random, time\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заранее прошу прощения за два цикла в функции, просто все утро боролся с капчей и не успел под один тег загнать."
      ],
      "metadata": {
        "id": "ltyrWwSwkYbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_images(url='https://www.ralphlauren.nl/en/men/clothing/hoodies-sweatshirts/10204?webcat=men%7Cclothing%7Cmen-clothing-hoodies-sweatshirts'):\n",
        "  counter = 0\n",
        "  proxy = FreeProxy(country_id=['NL'], https=True).get()\n",
        "  print(proxy)\n",
        "\n",
        "  for i in range(0, 129, 32):\n",
        "    r = requests.get(f'{url}&start={i}&gridBreakAttr=single-grid&sz=32', proxies={'http': proxy, 'https': proxy})\n",
        "    soup = BeautifulSoup(r.content, 'html.parser')\n",
        "    imgs = soup.find_all('div',  {\"class\": \"product-image\"})\n",
        "    prods = soup.find_all('div',  {\"class\": \"product-name\"})\n",
        "    # print(imgs)\n",
        "    # print(prods)\n",
        "    for img in imgs:\n",
        "              counter += 1\n",
        "              cloth_img_link = img.find('source', {'class': 'rlc-image-src-desktop'})['srcset']\n",
        "              res = requests.get(cloth_img_link, stream = True)\n",
        "              if res.status_code == 200:\n",
        "                  with open(f'/content/images/{counter}.jpg','wb') as f:\n",
        "                      shutil.copyfileobj(res.raw, f)\n",
        "                  print('Image sucessfully Downloaded: ', f'{counter}.jpg')\n",
        "              else:\n",
        "                  print('Image Couldn\\'t be retrieved')\n",
        "    counter = 0\n",
        "\n",
        "    for prod in prods:\n",
        "              counter += 1\n",
        "              name_link = prod.find('a', {'class': 'name-link'})['href']\n",
        "              name_link = 'https://www.ralphlauren.nl' + name_link\n",
        "\n",
        "              proxy = FreeProxy(country_id=['NL'], https=True).get()\n",
        "              try:\n",
        "                s_r = requests.get(name_link,  proxies={'http': proxy, 'https': proxy})\n",
        "              except requests.exceptions.ConnectionError:\n",
        "                print('Connection Error')\n",
        "                continue\n",
        "              if s_r.status_code == 200:\n",
        "                  s_r_soup = BeautifulSoup(s_r.content, 'html.parser')\n",
        "                  cloth_img_link = s_r_soup.find('img', {'aria-label': 'Product Image 2'})['data-img']\n",
        "                  res = requests.get(cloth_img_link, stream = True)\n",
        "                  if res.status_code == 200:\n",
        "                      with open(f'/content/images_2/{counter}.jpg','wb') as f:\n",
        "                          shutil.copyfileobj(res.raw, f)\n",
        "                          print('Image sucessfully Downloaded: ', f'{counter}.jpg')\n",
        "                  else:\n",
        "                          print('Image Couldn\\'t be retrieved')\n",
        "              else:\n",
        "                  continue"
      ],
      "metadata": {
        "id": "JvQ6jlD3dTyC"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_images()"
      ],
      "metadata": {
        "id": "Wfz-BSuad5iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZHlxiIIcyLWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}